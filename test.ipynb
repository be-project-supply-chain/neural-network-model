{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import pyltr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cost</th>\n",
       "      <th>location</th>\n",
       "      <th>speed</th>\n",
       "      <th>transit_time</th>\n",
       "      <th>four_pl_ratings</th>\n",
       "      <th>capacity</th>\n",
       "      <th>delays</th>\n",
       "      <th>total_deliveries</th>\n",
       "      <th>collaborative_partners</th>\n",
       "      <th>expertise</th>\n",
       "      <th>financial_stability</th>\n",
       "      <th>customer_ratings</th>\n",
       "      <th>hand_delivered</th>\n",
       "      <th>truck_delivered</th>\n",
       "      <th>overall_ratings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>26.14</td>\n",
       "      <td>9</td>\n",
       "      <td>25.30</td>\n",
       "      <td>35.31</td>\n",
       "      <td>3.25</td>\n",
       "      <td>130</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2185</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.91</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>39.64</td>\n",
       "      <td>7</td>\n",
       "      <td>27.71</td>\n",
       "      <td>21.52</td>\n",
       "      <td>4.13</td>\n",
       "      <td>458</td>\n",
       "      <td>0.92</td>\n",
       "      <td>4940</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.89</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>23.20</td>\n",
       "      <td>4</td>\n",
       "      <td>36.61</td>\n",
       "      <td>25.91</td>\n",
       "      <td>4.86</td>\n",
       "      <td>232</td>\n",
       "      <td>0.07</td>\n",
       "      <td>4730</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.72</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>23.06</td>\n",
       "      <td>5</td>\n",
       "      <td>33.46</td>\n",
       "      <td>28.70</td>\n",
       "      <td>3.72</td>\n",
       "      <td>143</td>\n",
       "      <td>0.14</td>\n",
       "      <td>4939</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.16</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>29.91</td>\n",
       "      <td>5</td>\n",
       "      <td>29.00</td>\n",
       "      <td>31.44</td>\n",
       "      <td>4.87</td>\n",
       "      <td>202</td>\n",
       "      <td>0.82</td>\n",
       "      <td>3664</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.80</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.60</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    cost  location  speed  transit_time  four_pl_ratings  capacity  delays  \\\n",
       "0  26.14         9  25.30         35.31             3.25       130    0.04   \n",
       "1  39.64         7  27.71         21.52             4.13       458    0.92   \n",
       "2  23.20         4  36.61         25.91             4.86       232    0.07   \n",
       "3  23.06         5  33.46         28.70             3.72       143    0.14   \n",
       "4  29.91         5  29.00         31.44             4.87       202    0.82   \n",
       "\n",
       "   total_deliveries  collaborative_partners  expertise  financial_stability  \\\n",
       "0              2185                       6          1                    1   \n",
       "1              4940                       9          1                    0   \n",
       "2              4730                       1          0                    1   \n",
       "3              4939                       9          1                    0   \n",
       "4              3664                       1          0                    1   \n",
       "\n",
       "   customer_ratings  hand_delivered  truck_delivered  overall_ratings  \n",
       "0              1.91               1                1             1.20  \n",
       "1              1.89               1                0             4.70  \n",
       "2              3.72               1                1             3.40  \n",
       "3              2.16               0                1             2.85  \n",
       "4              3.80               1                1             2.60  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_csv('./../sample-data.csv')\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cost</th>\n",
       "      <th>location</th>\n",
       "      <th>speed</th>\n",
       "      <th>transit_time</th>\n",
       "      <th>four_pl_ratings</th>\n",
       "      <th>capacity</th>\n",
       "      <th>delays</th>\n",
       "      <th>total_deliveries</th>\n",
       "      <th>collaborative_partners</th>\n",
       "      <th>expertise</th>\n",
       "      <th>financial_stability</th>\n",
       "      <th>customer_ratings</th>\n",
       "      <th>hand_delivered</th>\n",
       "      <th>truck_delivered</th>\n",
       "      <th>overall_ratings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>22.92</td>\n",
       "      <td>2</td>\n",
       "      <td>28.52</td>\n",
       "      <td>29.69</td>\n",
       "      <td>2.22</td>\n",
       "      <td>199</td>\n",
       "      <td>0.57</td>\n",
       "      <td>2893</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4.15</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>37.47</td>\n",
       "      <td>2</td>\n",
       "      <td>29.60</td>\n",
       "      <td>24.02</td>\n",
       "      <td>2.26</td>\n",
       "      <td>397</td>\n",
       "      <td>0.36</td>\n",
       "      <td>1583</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.73</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>26.05</td>\n",
       "      <td>2</td>\n",
       "      <td>25.85</td>\n",
       "      <td>38.20</td>\n",
       "      <td>3.54</td>\n",
       "      <td>406</td>\n",
       "      <td>0.26</td>\n",
       "      <td>3062</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.37</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>33.77</td>\n",
       "      <td>2</td>\n",
       "      <td>22.68</td>\n",
       "      <td>22.12</td>\n",
       "      <td>4.07</td>\n",
       "      <td>173</td>\n",
       "      <td>0.08</td>\n",
       "      <td>3690</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.69</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>25.53</td>\n",
       "      <td>2</td>\n",
       "      <td>33.28</td>\n",
       "      <td>22.27</td>\n",
       "      <td>4.07</td>\n",
       "      <td>443</td>\n",
       "      <td>0.14</td>\n",
       "      <td>2919</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.21</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>29.13</td>\n",
       "      <td>2</td>\n",
       "      <td>36.94</td>\n",
       "      <td>31.23</td>\n",
       "      <td>3.57</td>\n",
       "      <td>385</td>\n",
       "      <td>0.46</td>\n",
       "      <td>4503</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3.10</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231</th>\n",
       "      <td>36.26</td>\n",
       "      <td>2</td>\n",
       "      <td>24.58</td>\n",
       "      <td>32.23</td>\n",
       "      <td>3.45</td>\n",
       "      <td>241</td>\n",
       "      <td>0.85</td>\n",
       "      <td>1965</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.72</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258</th>\n",
       "      <td>29.59</td>\n",
       "      <td>2</td>\n",
       "      <td>24.17</td>\n",
       "      <td>36.31</td>\n",
       "      <td>3.62</td>\n",
       "      <td>427</td>\n",
       "      <td>0.25</td>\n",
       "      <td>3259</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3.39</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288</th>\n",
       "      <td>27.05</td>\n",
       "      <td>2</td>\n",
       "      <td>29.15</td>\n",
       "      <td>25.59</td>\n",
       "      <td>4.84</td>\n",
       "      <td>494</td>\n",
       "      <td>0.12</td>\n",
       "      <td>4959</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.78</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>22.52</td>\n",
       "      <td>2</td>\n",
       "      <td>28.54</td>\n",
       "      <td>35.04</td>\n",
       "      <td>1.50</td>\n",
       "      <td>105</td>\n",
       "      <td>0.54</td>\n",
       "      <td>1979</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.26</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>339</th>\n",
       "      <td>37.94</td>\n",
       "      <td>2</td>\n",
       "      <td>25.58</td>\n",
       "      <td>20.85</td>\n",
       "      <td>1.23</td>\n",
       "      <td>481</td>\n",
       "      <td>0.84</td>\n",
       "      <td>1928</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.11</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>367</th>\n",
       "      <td>21.12</td>\n",
       "      <td>2</td>\n",
       "      <td>34.80</td>\n",
       "      <td>29.54</td>\n",
       "      <td>1.11</td>\n",
       "      <td>281</td>\n",
       "      <td>0.78</td>\n",
       "      <td>4077</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4.97</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>384</th>\n",
       "      <td>30.43</td>\n",
       "      <td>2</td>\n",
       "      <td>22.87</td>\n",
       "      <td>30.94</td>\n",
       "      <td>4.63</td>\n",
       "      <td>230</td>\n",
       "      <td>0.93</td>\n",
       "      <td>3217</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4.66</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>435</th>\n",
       "      <td>36.63</td>\n",
       "      <td>2</td>\n",
       "      <td>36.92</td>\n",
       "      <td>29.43</td>\n",
       "      <td>4.83</td>\n",
       "      <td>403</td>\n",
       "      <td>0.59</td>\n",
       "      <td>4296</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.26</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>438</th>\n",
       "      <td>37.85</td>\n",
       "      <td>2</td>\n",
       "      <td>29.98</td>\n",
       "      <td>32.72</td>\n",
       "      <td>2.58</td>\n",
       "      <td>314</td>\n",
       "      <td>0.87</td>\n",
       "      <td>1156</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.29</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.90</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      cost  location  speed  transit_time  four_pl_ratings  capacity  delays  \\\n",
       "22   22.92         2  28.52         29.69             2.22       199    0.57   \n",
       "55   37.47         2  29.60         24.02             2.26       397    0.36   \n",
       "71   26.05         2  25.85         38.20             3.54       406    0.26   \n",
       "84   33.77         2  22.68         22.12             4.07       173    0.08   \n",
       "118  25.53         2  33.28         22.27             4.07       443    0.14   \n",
       "209  29.13         2  36.94         31.23             3.57       385    0.46   \n",
       "231  36.26         2  24.58         32.23             3.45       241    0.85   \n",
       "258  29.59         2  24.17         36.31             3.62       427    0.25   \n",
       "288  27.05         2  29.15         25.59             4.84       494    0.12   \n",
       "296  22.52         2  28.54         35.04             1.50       105    0.54   \n",
       "339  37.94         2  25.58         20.85             1.23       481    0.84   \n",
       "367  21.12         2  34.80         29.54             1.11       281    0.78   \n",
       "384  30.43         2  22.87         30.94             4.63       230    0.93   \n",
       "435  36.63         2  36.92         29.43             4.83       403    0.59   \n",
       "438  37.85         2  29.98         32.72             2.58       314    0.87   \n",
       "\n",
       "     total_deliveries  collaborative_partners  expertise  financial_stability  \\\n",
       "22               2893                       2          0                    1   \n",
       "55               1583                       2          0                    1   \n",
       "71               3062                       7          0                    0   \n",
       "84               3690                       9          0                    1   \n",
       "118              2919                       9          1                    1   \n",
       "209              4503                       5          1                    0   \n",
       "231              1965                       5          1                    1   \n",
       "258              3259                       2          1                    1   \n",
       "288              4959                       4          0                    1   \n",
       "296              1979                       8          1                    1   \n",
       "339              1928                       2          0                    0   \n",
       "367              4077                       4          0                    1   \n",
       "384              3217                       2          0                    1   \n",
       "435              4296                       7          1                    0   \n",
       "438              1156                       8          1                    0   \n",
       "\n",
       "     customer_ratings  hand_delivered  truck_delivered  overall_ratings  \n",
       "22               4.15               0                1             1.90  \n",
       "55               2.73               0                1             2.65  \n",
       "71               1.37               0                1             2.85  \n",
       "84               3.69               0                1             2.50  \n",
       "118              1.21               0                1             3.50  \n",
       "209              3.10               0                1             4.10  \n",
       "231              2.72               0                1             1.90  \n",
       "258              3.39               0                1             3.30  \n",
       "288              1.78               0                1             4.65  \n",
       "296              1.26               0                1             0.85  \n",
       "339              4.11               0                1             3.10  \n",
       "367              4.97               0                1             3.05  \n",
       "384              4.66               0                1             2.35  \n",
       "435              1.26               0                1             4.25  \n",
       "438              1.29               0                1             1.90  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.2  4.7  3.4  2.85 2.6  3.15 1.45 2.05 2.8  3.95 4.1  2.55 3.95 2.7\n",
      " 3.15 0.9  3.4  1.45 2.1  1.75 1.   4.05 1.9  4.   2.45 4.05 2.45 3.3\n",
      " 2.85 3.   2.6  3.1  3.5  2.15 1.7  2.15 3.9  4.2  2.75 3.7  4.15 4.15\n",
      " 2.6  2.8  1.15 2.3  3.4  1.3  3.05 2.25 1.95 1.4  1.65 4.25 1.9  2.65\n",
      " 3.55 2.2  4.   3.4  1.75 2.85 3.45 3.25 1.65 2.   0.7  2.5  2.9  3.6\n",
      " 1.3  2.85 3.8  2.8  1.3  4.4  3.35 2.8  3.6  4.25 1.4  3.05 1.9  3.3\n",
      " 2.5  1.8  2.6  3.25 1.85 3.   1.7  2.75 1.5  3.65 3.05 1.8  4.25 3.95\n",
      " 4.35 2.9  2.05 2.15 1.3  3.05 2.7  2.15 1.6  1.35 3.05 2.15 2.2  3.25\n",
      " 3.65 1.45 4.1  1.25 3.35 2.05 3.5  3.   2.1  3.45 2.4  3.25 3.45 3.1\n",
      " 4.15 3.05 3.35 2.1  1.7  2.8  1.65 1.15 1.25 2.65 2.4  2.2  2.85 3.95\n",
      " 2.95 4.1  2.8  2.85 0.9  2.5  2.8  2.35 2.5  3.75 2.8  3.2  3.5  3.05\n",
      " 1.9  3.6  3.5  2.75 1.5  1.8  1.7  4.2  1.7  2.3  4.75 3.1  1.45 3.75\n",
      " 2.3  2.1  2.05 3.2  1.9  1.7  4.3  2.7  2.7  3.05 2.   3.35 2.2  1.65\n",
      " 2.05 3.1  2.35 2.65 2.45 3.2  3.7  1.75 2.45 1.75 3.2  1.75 2.35 2.8\n",
      " 2.25 2.65 1.85 3.   1.35 2.45 3.25 3.3  2.35 2.2  3.2  1.8  1.5  4.1\n",
      " 2.6  4.1  4.25 2.1  2.6  3.05 2.7  1.3  3.5  3.35 2.75 1.25 3.3  2.3\n",
      " 2.95 3.15 2.35 3.7  2.8  1.8  4.   1.9  3.05 3.75 3.9  2.35 1.7  2.1\n",
      " 1.65 2.3  2.35 2.8  4.35 3.25 2.05 1.65 2.9  3.05 4.55 2.45 2.2  1.85\n",
      " 0.85 1.85 3.35 3.6  4.2  2.6  3.3  1.9  2.6  2.15 3.45 4.6  3.35 2.6\n",
      " 2.9  1.45 2.1  2.   2.4  2.65 1.85 2.75 2.85 1.95 3.25 4.65 3.3  3.6\n",
      " 2.1  3.3  2.3  2.5  2.1  3.3  3.35 3.3  4.65 2.05 2.3  2.75 2.05 1.9\n",
      " 1.7  1.1  0.85 1.6  2.2  1.75 1.1  2.75 2.4  2.75 4.55 2.35 2.1  2.95\n",
      " 3.75 2.9  1.7  3.25 3.55 3.5  3.55 2.6  2.55 4.05 4.45 2.4  3.25 2.45\n",
      " 2.25 2.45 3.25 2.55 2.95 2.5  3.35 4.15 1.45 1.6  3.05 4.15 2.25 2.9\n",
      " 3.25 2.55 2.05 3.1  1.7  2.85 2.75 2.05 2.75 1.5  1.25 2.6  3.85 2.5\n",
      " 1.9  2.05 1.2  3.2  1.7  3.75 2.2  1.4  2.15 2.3  3.1  1.7  3.4  1.75\n",
      " 2.25 2.5  1.05 3.05 1.15 2.75 2.25 3.25 2.95 2.35 1.85 4.25 2.5  0.75\n",
      " 3.65 2.8  1.55 2.3  3.15 3.45 2.35 2.6  3.15 1.65 1.05 4.05 3.7  3.\n",
      " 2.45 1.9  1.8  1.9  3.15 2.15 4.25 2.2  3.05 4.35 4.75 3.7  3.3  3.75\n",
      " 2.55 2.2  2.35 3.2  2.55 2.25 1.95 2.4  2.4  2.8  2.75 2.05 1.5  3.\n",
      " 2.1  3.45 2.25 2.9  2.4  1.75 3.95 2.8  3.2  3.25 3.35 1.75 3.05 1.7\n",
      " 2.2  4.25 3.2  2.55 1.9  2.95 3.85 1.75 1.35 2.85 3.2  1.05 3.6  3.85\n",
      " 2.05 3.   3.5  3.05 3.4  4.5  2.5  2.5  1.1  2.65 3.1  3.55 2.4  2.1\n",
      " 2.55 4.5  1.35 3.05 1.05 3.6  2.65 2.65 2.75 3.15 1.6  4.   2.   1.75\n",
      " 2.35 2.4  3.65 2.45 2.7  2.7  4.25 3.75 2.3  2.15 1.6  4.4  1.5  1.3\n",
      " 4.15 2.15 2.5  1.25 3.3  4.45 2.9  2.15 3.1  1.05]\n"
     ]
    }
   ],
   "source": [
    "X = dataset.iloc[:,dataset.columns!='overall_ratings'].values\n",
    "y = dataset.iloc[ : , 14 ].values\n",
    "# type(dataset.iloc[:4,5:10])\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "# labelencoder_X_1 = LabelEncoder()\n",
    "# X[:, 1] = labelencoder_X_1.fit_transform(X[:, 1])\n",
    "# labelencoder_X_2 = LabelEncoder()\n",
    "# X[:, 2] = labelencoder_X_2.fit_transform(X[:, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "# onehotencoder = OneHotEncoder(categorical_features = [1])\n",
    "#  X = onehotencoder.fit_transform(X).toarray()\n",
    "# X = X[:, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.016e+01, 7.000e+00, 2.894e+01, 2.509e+01, 1.930e+00, 4.870e+02,\n",
       "       2.800e-01, 2.983e+03, 9.000e+00, 1.000e+00, 0.000e+00, 2.940e+00,\n",
       "       1.000e+00, 1.000e+00])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)\n",
    "X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.59388548,  0.84523551, -0.24618463, -0.96000692, -0.90951216,\n",
       "        1.55571703, -0.64373514,  0.03824464,  1.53261385,  1.0100505 ,\n",
       "       -0.97530483, -0.09462484,  0.95118973,  0.57735027])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)\n",
    "X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 14)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0:1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\pramo\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:1: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", input_dim=14, units=14, kernel_initializer=\"uniform\")`\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "c:\\users\\pramo\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:3: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=14, kernel_initializer=\"uniform\")`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "c:\\users\\pramo\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:5: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=14, kernel_initializer=\"uniform\")`\n",
      "  \"\"\"\n",
      "c:\\users\\pramo\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=1, kernel_initializer=\"uniform\")`\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "model.add(Dense(output_dim = 14, init = 'uniform', activation = 'relu', input_dim = 14))\n",
    "# Adding the second hidden layer\n",
    "model.add(Dense(output_dim = 14, init = 'uniform', activation = 'relu'))\n",
    "\n",
    "model.add(Dense(output_dim = 14, init = 'uniform', activation = 'relu'))\n",
    "# Adding the output layer\n",
    "model.add(Dense(output_dim = 1, init = 'uniform', activation = 'relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer = 'adam', loss = 'mean_squared_error', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "400/400 [==============================] - 0s 35us/step - loss: 0.0096 - acc: 0.0375\n",
      "Epoch 2/200\n",
      "400/400 [==============================] - 0s 27us/step - loss: 0.0096 - acc: 0.0375\n",
      "Epoch 3/200\n",
      "400/400 [==============================] - 0s 22us/step - loss: 0.0095 - acc: 0.0375\n",
      "Epoch 4/200\n",
      "400/400 [==============================] - 0s 27us/step - loss: 0.0095 - acc: 0.0375\n",
      "Epoch 5/200\n",
      "400/400 [==============================] - 0s 28us/step - loss: 0.0094 - acc: 0.0375\n",
      "Epoch 6/200\n",
      "400/400 [==============================] - 0s 35us/step - loss: 0.0093 - acc: 0.0375\n",
      "Epoch 7/200\n",
      "400/400 [==============================] - 0s 40us/step - loss: 0.0094 - acc: 0.0375\n",
      "Epoch 8/200\n",
      "400/400 [==============================] - 0s 40us/step - loss: 0.0093 - acc: 0.0375\n",
      "Epoch 9/200\n",
      "400/400 [==============================] - 0s 30us/step - loss: 0.0092 - acc: 0.0375\n",
      "Epoch 10/200\n",
      "400/400 [==============================] - 0s 27us/step - loss: 0.0091 - acc: 0.0375\n",
      "Epoch 11/200\n",
      "400/400 [==============================] - 0s 27us/step - loss: 0.0091 - acc: 0.0375\n",
      "Epoch 12/200\n",
      "400/400 [==============================] - 0s 30us/step - loss: 0.0091 - acc: 0.0375\n",
      "Epoch 13/200\n",
      " 50/400 [==>...........................] - ETA: 0s - loss: 0.0074 - acc: 0.0200"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\pramo\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:4: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400/400 [==============================] - 0s 32us/step - loss: 0.0090 - acc: 0.0375\n",
      "Epoch 14/200\n",
      "400/400 [==============================] - 0s 27us/step - loss: 0.0089 - acc: 0.0375\n",
      "Epoch 15/200\n",
      "400/400 [==============================] - 0s 30us/step - loss: 0.0090 - acc: 0.0375\n",
      "Epoch 16/200\n",
      "400/400 [==============================] - 0s 30us/step - loss: 0.0090 - acc: 0.0375\n",
      "Epoch 17/200\n",
      "400/400 [==============================] - 0s 25us/step - loss: 0.0089 - acc: 0.0375\n",
      "Epoch 18/200\n",
      "400/400 [==============================] - 0s 25us/step - loss: 0.0089 - acc: 0.0375\n",
      "Epoch 19/200\n",
      "400/400 [==============================] - 0s 27us/step - loss: 0.0089 - acc: 0.0375\n",
      "Epoch 20/200\n",
      "400/400 [==============================] - 0s 32us/step - loss: 0.0088 - acc: 0.0375\n",
      "Epoch 21/200\n",
      "400/400 [==============================] - 0s 27us/step - loss: 0.0087 - acc: 0.0375\n",
      "Epoch 22/200\n",
      "400/400 [==============================] - 0s 30us/step - loss: 0.0086 - acc: 0.0375\n",
      "Epoch 23/200\n",
      "400/400 [==============================] - 0s 25us/step - loss: 0.0086 - acc: 0.0375\n",
      "Epoch 24/200\n",
      "400/400 [==============================] - 0s 27us/step - loss: 0.0085 - acc: 0.0375\n",
      "Epoch 25/200\n",
      "400/400 [==============================] - 0s 25us/step - loss: 0.0085 - acc: 0.0375\n",
      "Epoch 26/200\n",
      "400/400 [==============================] - 0s 30us/step - loss: 0.0084 - acc: 0.0375\n",
      "Epoch 27/200\n",
      "400/400 [==============================] - 0s 27us/step - loss: 0.0084 - acc: 0.0375\n",
      "Epoch 28/200\n",
      "400/400 [==============================] - 0s 25us/step - loss: 0.0084 - acc: 0.0375\n",
      "Epoch 29/200\n",
      "400/400 [==============================] - 0s 25us/step - loss: 0.0084 - acc: 0.0375\n",
      "Epoch 30/200\n",
      "400/400 [==============================] - 0s 27us/step - loss: 0.0082 - acc: 0.0375\n",
      "Epoch 31/200\n",
      "400/400 [==============================] - 0s 27us/step - loss: 0.0082 - acc: 0.0375\n",
      "Epoch 32/200\n",
      "400/400 [==============================] - 0s 30us/step - loss: 0.0082 - acc: 0.0375\n",
      "Epoch 33/200\n",
      "400/400 [==============================] - 0s 30us/step - loss: 0.0081 - acc: 0.0375\n",
      "Epoch 34/200\n",
      "400/400 [==============================] - 0s 27us/step - loss: 0.0080 - acc: 0.0375\n",
      "Epoch 35/200\n",
      "400/400 [==============================] - 0s 27us/step - loss: 0.0081 - acc: 0.0375\n",
      "Epoch 36/200\n",
      "400/400 [==============================] - 0s 27us/step - loss: 0.0080 - acc: 0.0375\n",
      "Epoch 37/200\n",
      "400/400 [==============================] - 0s 32us/step - loss: 0.0081 - acc: 0.0375\n",
      "Epoch 38/200\n",
      "400/400 [==============================] - 0s 27us/step - loss: 0.0079 - acc: 0.0375\n",
      "Epoch 39/200\n",
      "400/400 [==============================] - 0s 20us/step - loss: 0.0081 - acc: 0.0375\n",
      "Epoch 40/200\n",
      "400/400 [==============================] - 0s 30us/step - loss: 0.0080 - acc: 0.0375\n",
      "Epoch 41/200\n",
      "400/400 [==============================] - 0s 32us/step - loss: 0.0078 - acc: 0.0375\n",
      "Epoch 42/200\n",
      "400/400 [==============================] - 0s 32us/step - loss: 0.0078 - acc: 0.0375\n",
      "Epoch 43/200\n",
      "400/400 [==============================] - 0s 27us/step - loss: 0.0078 - acc: 0.0375\n",
      "Epoch 44/200\n",
      "400/400 [==============================] - 0s 25us/step - loss: 0.0077 - acc: 0.0375\n",
      "Epoch 45/200\n",
      "400/400 [==============================] - 0s 30us/step - loss: 0.0077 - acc: 0.0375\n",
      "Epoch 46/200\n",
      "400/400 [==============================] - 0s 35us/step - loss: 0.0076 - acc: 0.0375\n",
      "Epoch 47/200\n",
      "400/400 [==============================] - 0s 27us/step - loss: 0.0076 - acc: 0.0375\n",
      "Epoch 48/200\n",
      "400/400 [==============================] - 0s 25us/step - loss: 0.0075 - acc: 0.0375\n",
      "Epoch 49/200\n",
      "400/400 [==============================] - 0s 25us/step - loss: 0.0075 - acc: 0.0375\n",
      "Epoch 50/200\n",
      "400/400 [==============================] - 0s 32us/step - loss: 0.0074 - acc: 0.0375\n",
      "Epoch 51/200\n",
      "400/400 [==============================] - 0s 22us/step - loss: 0.0074 - acc: 0.0375\n",
      "Epoch 52/200\n",
      "400/400 [==============================] - 0s 25us/step - loss: 0.0074 - acc: 0.0375\n",
      "Epoch 53/200\n",
      "400/400 [==============================] - 0s 30us/step - loss: 0.0074 - acc: 0.0375\n",
      "Epoch 54/200\n",
      "400/400 [==============================] - 0s 25us/step - loss: 0.0073 - acc: 0.0375\n",
      "Epoch 55/200\n",
      "400/400 [==============================] - 0s 20us/step - loss: 0.0073 - acc: 0.0375\n",
      "Epoch 56/200\n",
      "400/400 [==============================] - 0s 20us/step - loss: 0.0074 - acc: 0.0375\n",
      "Epoch 57/200\n",
      "400/400 [==============================] - 0s 32us/step - loss: 0.0074 - acc: 0.0375\n",
      "Epoch 58/200\n",
      "400/400 [==============================] - 0s 25us/step - loss: 0.0073 - acc: 0.0375\n",
      "Epoch 59/200\n",
      "400/400 [==============================] - 0s 32us/step - loss: 0.0071 - acc: 0.0375\n",
      "Epoch 60/200\n",
      "400/400 [==============================] - 0s 22us/step - loss: 0.0071 - acc: 0.0375\n",
      "Epoch 61/200\n",
      "400/400 [==============================] - 0s 35us/step - loss: 0.0071 - acc: 0.0375\n",
      "Epoch 62/200\n",
      "400/400 [==============================] - 0s 27us/step - loss: 0.0071 - acc: 0.0375\n",
      "Epoch 63/200\n",
      "400/400 [==============================] - 0s 25us/step - loss: 0.0070 - acc: 0.0375\n",
      "Epoch 64/200\n",
      "400/400 [==============================] - 0s 35us/step - loss: 0.0070 - acc: 0.0375\n",
      "Epoch 65/200\n",
      "400/400 [==============================] - 0s 22us/step - loss: 0.0069 - acc: 0.0375\n",
      "Epoch 66/200\n",
      "400/400 [==============================] - 0s 32us/step - loss: 0.0070 - acc: 0.0375\n",
      "Epoch 67/200\n",
      "400/400 [==============================] - 0s 30us/step - loss: 0.0069 - acc: 0.0375\n",
      "Epoch 68/200\n",
      "400/400 [==============================] - 0s 32us/step - loss: 0.0070 - acc: 0.0375\n",
      "Epoch 69/200\n",
      "400/400 [==============================] - 0s 30us/step - loss: 0.0069 - acc: 0.0375\n",
      "Epoch 70/200\n",
      "400/400 [==============================] - 0s 40us/step - loss: 0.0068 - acc: 0.0375\n",
      "Epoch 71/200\n",
      "400/400 [==============================] - ETA: 0s - loss: 0.0226 - acc: 0.020 - 0s 37us/step - loss: 0.0069 - acc: 0.0375\n",
      "Epoch 72/200\n",
      "400/400 [==============================] - 0s 35us/step - loss: 0.0068 - acc: 0.0375\n",
      "Epoch 73/200\n",
      "400/400 [==============================] - 0s 22us/step - loss: 0.0070 - acc: 0.0375\n",
      "Epoch 74/200\n",
      "400/400 [==============================] - 0s 27us/step - loss: 0.0069 - acc: 0.0375\n",
      "Epoch 75/200\n",
      "400/400 [==============================] - 0s 27us/step - loss: 0.0071 - acc: 0.0375\n",
      "Epoch 76/200\n",
      "400/400 [==============================] - 0s 40us/step - loss: 0.0067 - acc: 0.0375\n",
      "Epoch 77/200\n",
      "400/400 [==============================] - 0s 17us/step - loss: 0.0067 - acc: 0.0375\n",
      "Epoch 78/200\n",
      "400/400 [==============================] - 0s 30us/step - loss: 0.0067 - acc: 0.0375\n",
      "Epoch 79/200\n",
      "400/400 [==============================] - 0s 27us/step - loss: 0.0066 - acc: 0.0375\n",
      "Epoch 80/200\n",
      "400/400 [==============================] - 0s 25us/step - loss: 0.0066 - acc: 0.0375\n",
      "Epoch 81/200\n",
      "400/400 [==============================] - 0s 30us/step - loss: 0.0065 - acc: 0.0375\n",
      "Epoch 82/200\n",
      "400/400 [==============================] - 0s 27us/step - loss: 0.0066 - acc: 0.0375\n",
      "Epoch 83/200\n",
      "400/400 [==============================] - 0s 25us/step - loss: 0.0066 - acc: 0.0375\n",
      "Epoch 84/200\n",
      "400/400 [==============================] - 0s 22us/step - loss: 0.0065 - acc: 0.0375\n",
      "Epoch 85/200\n",
      "400/400 [==============================] - 0s 20us/step - loss: 0.0065 - acc: 0.0375\n",
      "Epoch 86/200\n",
      "400/400 [==============================] - 0s 35us/step - loss: 0.0065 - acc: 0.0375\n",
      "Epoch 87/200\n",
      "400/400 [==============================] - 0s 27us/step - loss: 0.0066 - acc: 0.0375\n",
      "Epoch 88/200\n",
      "400/400 [==============================] - 0s 27us/step - loss: 0.0066 - acc: 0.0375\n",
      "Epoch 89/200\n",
      "400/400 [==============================] - 0s 17us/step - loss: 0.0065 - acc: 0.0375\n",
      "Epoch 90/200\n",
      "400/400 [==============================] - 0s 22us/step - loss: 0.0064 - acc: 0.0375\n",
      "Epoch 91/200\n",
      "400/400 [==============================] - 0s 30us/step - loss: 0.0065 - acc: 0.0375\n",
      "Epoch 92/200\n",
      "400/400 [==============================] - 0s 17us/step - loss: 0.0064 - acc: 0.0375\n",
      "Epoch 93/200\n",
      "400/400 [==============================] - 0s 22us/step - loss: 0.0063 - acc: 0.0375\n",
      "Epoch 94/200\n",
      "400/400 [==============================] - 0s 22us/step - loss: 0.0063 - acc: 0.0375\n",
      "Epoch 95/200\n",
      "400/400 [==============================] - 0s 20us/step - loss: 0.0063 - acc: 0.0375\n",
      "Epoch 96/200\n",
      "400/400 [==============================] - 0s 32us/step - loss: 0.0063 - acc: 0.0375\n",
      "Epoch 97/200\n",
      "400/400 [==============================] - 0s 20us/step - loss: 0.0062 - acc: 0.0375\n",
      "Epoch 98/200\n",
      "400/400 [==============================] - 0s 30us/step - loss: 0.0063 - acc: 0.0375\n",
      "Epoch 99/200\n",
      "400/400 [==============================] - 0s 22us/step - loss: 0.0063 - acc: 0.0375\n",
      "Epoch 100/200\n",
      "400/400 [==============================] - 0s 20us/step - loss: 0.0062 - acc: 0.0375\n",
      "Epoch 101/200\n",
      "400/400 [==============================] - 0s 30us/step - loss: 0.0063 - acc: 0.0375\n",
      "Epoch 102/200\n",
      "400/400 [==============================] - 0s 25us/step - loss: 0.0062 - acc: 0.0375\n",
      "Epoch 103/200\n",
      "400/400 [==============================] - 0s 27us/step - loss: 0.0062 - acc: 0.0375\n",
      "Epoch 104/200\n",
      "400/400 [==============================] - 0s 20us/step - loss: 0.0061 - acc: 0.0375\n",
      "Epoch 105/200\n",
      "400/400 [==============================] - 0s 27us/step - loss: 0.0061 - acc: 0.0375\n",
      "Epoch 106/200\n",
      "400/400 [==============================] - 0s 25us/step - loss: 0.0061 - acc: 0.0375\n",
      "Epoch 107/200\n",
      "400/400 [==============================] - 0s 20us/step - loss: 0.0061 - acc: 0.0375\n",
      "Epoch 108/200\n",
      "400/400 [==============================] - 0s 22us/step - loss: 0.0061 - acc: 0.0375\n",
      "Epoch 109/200\n",
      "400/400 [==============================] - 0s 25us/step - loss: 0.0061 - acc: 0.0375\n",
      "Epoch 110/200\n",
      "400/400 [==============================] - 0s 20us/step - loss: 0.0060 - acc: 0.0375\n",
      "Epoch 111/200\n",
      "400/400 [==============================] - 0s 22us/step - loss: 0.0060 - acc: 0.0375\n",
      "Epoch 112/200\n",
      "400/400 [==============================] - 0s 27us/step - loss: 0.0060 - acc: 0.0375\n",
      "Epoch 113/200\n",
      "400/400 [==============================] - 0s 20us/step - loss: 0.0060 - acc: 0.0375\n",
      "Epoch 114/200\n",
      "400/400 [==============================] - 0s 25us/step - loss: 0.0059 - acc: 0.0375\n",
      "Epoch 115/200\n",
      "400/400 [==============================] - 0s 25us/step - loss: 0.0059 - acc: 0.0375\n",
      "Epoch 116/200\n",
      "400/400 [==============================] - 0s 22us/step - loss: 0.0060 - acc: 0.0375\n",
      "Epoch 117/200\n",
      "400/400 [==============================] - 0s 22us/step - loss: 0.0060 - acc: 0.0375\n",
      "Epoch 118/200\n",
      "400/400 [==============================] - 0s 25us/step - loss: 0.0060 - acc: 0.0375\n",
      "Epoch 119/200\n",
      "400/400 [==============================] - 0s 22us/step - loss: 0.0060 - acc: 0.0375\n",
      "Epoch 120/200\n",
      "400/400 [==============================] - 0s 25us/step - loss: 0.0062 - acc: 0.0375\n",
      "Epoch 121/200\n",
      "400/400 [==============================] - 0s 32us/step - loss: 0.0059 - acc: 0.0375\n",
      "Epoch 122/200\n",
      "400/400 [==============================] - 0s 40us/step - loss: 0.0059 - acc: 0.0375\n",
      "Epoch 123/200\n",
      "400/400 [==============================] - 0s 27us/step - loss: 0.0058 - acc: 0.0375\n",
      "Epoch 124/200\n",
      "400/400 [==============================] - 0s 32us/step - loss: 0.0058 - acc: 0.0375\n",
      "Epoch 125/200\n",
      "400/400 [==============================] - 0s 30us/step - loss: 0.0058 - acc: 0.0375\n",
      "Epoch 126/200\n",
      "400/400 [==============================] - 0s 30us/step - loss: 0.0057 - acc: 0.0375\n",
      "Epoch 127/200\n",
      "400/400 [==============================] - 0s 22us/step - loss: 0.0057 - acc: 0.0375\n",
      "Epoch 128/200\n",
      "400/400 [==============================] - 0s 27us/step - loss: 0.0057 - acc: 0.0375\n",
      "Epoch 129/200\n",
      "400/400 [==============================] - 0s 27us/step - loss: 0.0057 - acc: 0.0375\n",
      "Epoch 130/200\n",
      "400/400 [==============================] - 0s 22us/step - loss: 0.0057 - acc: 0.0375\n",
      "Epoch 131/200\n",
      "400/400 [==============================] - 0s 22us/step - loss: 0.0056 - acc: 0.0375\n",
      "Epoch 132/200\n",
      "400/400 [==============================] - ETA: 0s - loss: 0.0024 - acc: 0.080 - 0s 25us/step - loss: 0.0057 - acc: 0.0375\n",
      "Epoch 133/200\n",
      "400/400 [==============================] - 0s 30us/step - loss: 0.0056 - acc: 0.0375\n",
      "Epoch 134/200\n",
      "400/400 [==============================] - 0s 22us/step - loss: 0.0057 - acc: 0.0375\n",
      "Epoch 135/200\n",
      "400/400 [==============================] - 0s 25us/step - loss: 0.0057 - acc: 0.0375\n",
      "Epoch 136/200\n",
      "400/400 [==============================] - 0s 25us/step - loss: 0.0056 - acc: 0.0375\n",
      "Epoch 137/200\n",
      "400/400 [==============================] - 0s 20us/step - loss: 0.0056 - acc: 0.0375\n",
      "Epoch 138/200\n",
      "400/400 [==============================] - 0s 27us/step - loss: 0.0056 - acc: 0.0375\n",
      "Epoch 139/200\n",
      "400/400 [==============================] - 0s 32us/step - loss: 0.0055 - acc: 0.0375\n",
      "Epoch 140/200\n",
      "400/400 [==============================] - ETA: 0s - loss: 0.0028 - acc: 0.0000e+0 - 0s 25us/step - loss: 0.0055 - acc: 0.0375\n",
      "Epoch 141/200\n",
      "400/400 [==============================] - 0s 25us/step - loss: 0.0055 - acc: 0.0375\n",
      "Epoch 142/200\n",
      "400/400 [==============================] - 0s 30us/step - loss: 0.0055 - acc: 0.0375\n",
      "Epoch 143/200\n",
      "400/400 [==============================] - 0s 30us/step - loss: 0.0055 - acc: 0.0375\n",
      "Epoch 144/200\n",
      "400/400 [==============================] - 0s 32us/step - loss: 0.0054 - acc: 0.0375\n",
      "Epoch 145/200\n",
      "400/400 [==============================] - 0s 30us/step - loss: 0.0053 - acc: 0.0375\n",
      "Epoch 146/200\n",
      "400/400 [==============================] - 0s 22us/step - loss: 0.0053 - acc: 0.0375\n",
      "Epoch 147/200\n",
      "400/400 [==============================] - 0s 30us/step - loss: 0.0053 - acc: 0.0375\n",
      "Epoch 148/200\n",
      "400/400 [==============================] - 0s 22us/step - loss: 0.0053 - acc: 0.0375\n",
      "Epoch 149/200\n",
      "400/400 [==============================] - 0s 17us/step - loss: 0.0054 - acc: 0.0375\n",
      "Epoch 150/200\n",
      "400/400 [==============================] - 0s 27us/step - loss: 0.0054 - acc: 0.0375\n",
      "Epoch 151/200\n",
      "400/400 [==============================] - 0s 30us/step - loss: 0.0053 - acc: 0.0375\n",
      "Epoch 152/200\n",
      "400/400 [==============================] - 0s 30us/step - loss: 0.0052 - acc: 0.0375\n",
      "Epoch 153/200\n",
      "400/400 [==============================] - 0s 20us/step - loss: 0.0053 - acc: 0.0375\n",
      "Epoch 154/200\n",
      "400/400 [==============================] - 0s 27us/step - loss: 0.0053 - acc: 0.0375\n",
      "Epoch 155/200\n",
      "400/400 [==============================] - ETA: 0s - loss: 0.0043 - acc: 0.080 - 0s 30us/step - loss: 0.0052 - acc: 0.0375\n",
      "Epoch 156/200\n",
      "400/400 [==============================] - 0s 22us/step - loss: 0.0052 - acc: 0.0375\n",
      "Epoch 157/200\n",
      "400/400 [==============================] - 0s 30us/step - loss: 0.0051 - acc: 0.0375\n",
      "Epoch 158/200\n",
      "400/400 [==============================] - 0s 27us/step - loss: 0.0052 - acc: 0.0375\n",
      "Epoch 159/200\n",
      "400/400 [==============================] - 0s 25us/step - loss: 0.0051 - acc: 0.0375\n",
      "Epoch 160/200\n",
      "400/400 [==============================] - 0s 20us/step - loss: 0.0052 - acc: 0.0375\n",
      "Epoch 161/200\n",
      "400/400 [==============================] - 0s 22us/step - loss: 0.0051 - acc: 0.0375\n",
      "Epoch 162/200\n",
      "400/400 [==============================] - 0s 30us/step - loss: 0.0051 - acc: 0.0375\n",
      "Epoch 163/200\n",
      "400/400 [==============================] - 0s 17us/step - loss: 0.0050 - acc: 0.0375\n",
      "Epoch 164/200\n",
      "400/400 [==============================] - 0s 25us/step - loss: 0.0052 - acc: 0.0375\n",
      "Epoch 165/200\n",
      "400/400 [==============================] - 0s 30us/step - loss: 0.0050 - acc: 0.0375\n",
      "Epoch 166/200\n",
      "400/400 [==============================] - 0s 20us/step - loss: 0.0051 - acc: 0.0375\n",
      "Epoch 167/200\n",
      "400/400 [==============================] - 0s 22us/step - loss: 0.0050 - acc: 0.0375\n",
      "Epoch 168/200\n",
      "400/400 [==============================] - 0s 30us/step - loss: 0.0050 - acc: 0.0375\n",
      "Epoch 169/200\n",
      "400/400 [==============================] - 0s 22us/step - loss: 0.0049 - acc: 0.0375\n",
      "Epoch 170/200\n",
      "400/400 [==============================] - 0s 20us/step - loss: 0.0050 - acc: 0.0375\n",
      "Epoch 171/200\n",
      "400/400 [==============================] - 0s 27us/step - loss: 0.0050 - acc: 0.0375\n",
      "Epoch 172/200\n",
      "400/400 [==============================] - 0s 17us/step - loss: 0.0049 - acc: 0.0375\n",
      "Epoch 173/200\n",
      "400/400 [==============================] - 0s 25us/step - loss: 0.0049 - acc: 0.0375\n",
      "Epoch 174/200\n",
      "400/400 [==============================] - 0s 22us/step - loss: 0.0049 - acc: 0.0375\n",
      "Epoch 175/200\n",
      "400/400 [==============================] - 0s 17us/step - loss: 0.0049 - acc: 0.0375\n",
      "Epoch 176/200\n",
      "400/400 [==============================] - 0s 25us/step - loss: 0.0049 - acc: 0.0375\n",
      "Epoch 177/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400/400 [==============================] - 0s 25us/step - loss: 0.0048 - acc: 0.0375\n",
      "Epoch 178/200\n",
      "400/400 [==============================] - 0s 25us/step - loss: 0.0048 - acc: 0.0375\n",
      "Epoch 179/200\n",
      "400/400 [==============================] - 0s 22us/step - loss: 0.0048 - acc: 0.0375\n",
      "Epoch 180/200\n",
      "400/400 [==============================] - 0s 30us/step - loss: 0.0049 - acc: 0.0375\n",
      "Epoch 181/200\n",
      "400/400 [==============================] - 0s 20us/step - loss: 0.0048 - acc: 0.0375\n",
      "Epoch 182/200\n",
      "400/400 [==============================] - 0s 20us/step - loss: 0.0048 - acc: 0.0375\n",
      "Epoch 183/200\n",
      "400/400 [==============================] - 0s 32us/step - loss: 0.0048 - acc: 0.0375\n",
      "Epoch 184/200\n",
      "400/400 [==============================] - 0s 27us/step - loss: 0.0048 - acc: 0.0375\n",
      "Epoch 185/200\n",
      "400/400 [==============================] - 0s 22us/step - loss: 0.0048 - acc: 0.0375\n",
      "Epoch 186/200\n",
      "400/400 [==============================] - 0s 30us/step - loss: 0.0047 - acc: 0.0375\n",
      "Epoch 187/200\n",
      "400/400 [==============================] - 0s 25us/step - loss: 0.0048 - acc: 0.0375\n",
      "Epoch 188/200\n",
      "400/400 [==============================] - ETA: 0s - loss: 0.0026 - acc: 0.060 - 0s 22us/step - loss: 0.0047 - acc: 0.0375\n",
      "Epoch 189/200\n",
      "400/400 [==============================] - 0s 32us/step - loss: 0.0047 - acc: 0.0375\n",
      "Epoch 190/200\n",
      "400/400 [==============================] - 0s 30us/step - loss: 0.0047 - acc: 0.0375\n",
      "Epoch 191/200\n",
      "400/400 [==============================] - 0s 20us/step - loss: 0.0047 - acc: 0.0375\n",
      "Epoch 192/200\n",
      "400/400 [==============================] - 0s 27us/step - loss: 0.0046 - acc: 0.0375\n",
      "Epoch 193/200\n",
      "400/400 [==============================] - 0s 30us/step - loss: 0.0046 - acc: 0.0375\n",
      "Epoch 194/200\n",
      "400/400 [==============================] - 0s 25us/step - loss: 0.0046 - acc: 0.0375\n",
      "Epoch 195/200\n",
      "400/400 [==============================] - 0s 27us/step - loss: 0.0046 - acc: 0.0375\n",
      "Epoch 196/200\n",
      "400/400 [==============================] - 0s 25us/step - loss: 0.0047 - acc: 0.0375\n",
      "Epoch 197/200\n",
      "400/400 [==============================] - 0s 27us/step - loss: 0.0046 - acc: 0.0375\n",
      "Epoch 198/200\n",
      "400/400 [==============================] - 0s 30us/step - loss: 0.0045 - acc: 0.0375\n",
      "Epoch 199/200\n",
      "400/400 [==============================] - 0s 25us/step - loss: 0.0046 - acc: 0.0375\n",
      "Epoch 200/200\n",
      "400/400 [==============================] - 0s 27us/step - loss: 0.0045 - acc: 0.0375\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a67bcd3198>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "# early_stopping_monitor = EarlyStopping(patience=3)\n",
    "model.fit(X_train, y_train, batch_size = 50, nb_epoch = 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2.108645 ]\n",
      " [2.0251646]\n",
      " [3.1216073]\n",
      " [1.2283703]\n",
      " [1.3122321]\n",
      " [2.2424428]\n",
      " [2.2701657]\n",
      " [3.1845696]\n",
      " [3.1478739]\n",
      " [3.218836 ]\n",
      " [2.169894 ]\n",
      " [1.975195 ]\n",
      " [4.497626 ]\n",
      " [2.753213 ]\n",
      " [1.6244763]\n",
      " [1.9946005]\n",
      " [2.2031178]\n",
      " [1.8876631]\n",
      " [2.1215086]\n",
      " [4.090959 ]\n",
      " [3.0066242]\n",
      " [2.4832485]\n",
      " [2.903482 ]\n",
      " [4.2545233]\n",
      " [3.0465257]\n",
      " [4.8910217]\n",
      " [2.635883 ]\n",
      " [2.4259298]\n",
      " [1.5218849]\n",
      " [2.115743 ]\n",
      " [2.052709 ]\n",
      " [1.763027 ]\n",
      " [1.4364815]\n",
      " [4.5593863]\n",
      " [2.1156676]\n",
      " [4.047867 ]\n",
      " [2.8490906]\n",
      " [3.3428116]\n",
      " [1.9954967]\n",
      " [2.7388985]\n",
      " [1.2937123]\n",
      " [1.9943851]\n",
      " [3.7476103]\n",
      " [2.1684573]\n",
      " [2.547419 ]\n",
      " [4.364753 ]\n",
      " [1.621463 ]\n",
      " [1.7268335]\n",
      " [2.5796793]\n",
      " [2.62335  ]\n",
      " [2.02792  ]\n",
      " [1.8841099]\n",
      " [3.1351156]\n",
      " [3.2552059]\n",
      " [2.4924178]\n",
      " [3.1417391]\n",
      " [1.6481535]\n",
      " [1.8513592]\n",
      " [1.4070581]\n",
      " [3.0900242]\n",
      " [4.301836 ]\n",
      " [4.673647 ]\n",
      " [2.8037198]\n",
      " [2.0048542]\n",
      " [1.9393175]\n",
      " [2.062118 ]\n",
      " [2.6403375]\n",
      " [4.0788116]\n",
      " [4.5867343]\n",
      " [2.7067137]\n",
      " [2.8525019]\n",
      " [3.3028207]\n",
      " [3.3757572]\n",
      " [3.238573 ]\n",
      " [3.492497 ]\n",
      " [3.013503 ]\n",
      " [3.1398034]\n",
      " [2.2033348]\n",
      " [4.380171 ]\n",
      " [4.0095897]\n",
      " [2.4486487]\n",
      " [2.5051754]\n",
      " [3.6086676]\n",
      " [1.172882 ]\n",
      " [2.720897 ]\n",
      " [1.1305692]\n",
      " [1.4203025]\n",
      " [1.5958054]\n",
      " [4.302287 ]\n",
      " [1.4877259]\n",
      " [1.6146865]\n",
      " [4.6486354]\n",
      " [3.449487 ]\n",
      " [1.7908678]\n",
      " [3.4808986]\n",
      " [3.2998433]\n",
      " [1.4166096]\n",
      " [1.9704484]\n",
      " [1.4676751]\n",
      " [3.1949093]]\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "print(y_pred)\n",
    "# y_pred = (y_pred > 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9902197477232374"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from sklearn.metrics import confusion_matrix\n",
    "# cm = confusion_matrix(y_test, y_pred)\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "scores = r2_score(y_pred, y_test)\n",
    "scores\n",
    "# accuracy=(cm[0][0]+cm[0][1])/(cm[0][0]+cm[0][1]+cm[1][0]+cm[1][1])\n",
    "# accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Singleton array True cannot be considered a valid collection.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-167-59075f330b81>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     15\u001b[0m )\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0many\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\users\\pramo\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\pyltr\\models\\lambdamart.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, qids, monitor)\u001b[0m\n\u001b[0;32m    171\u001b[0m         \u001b[0mn_samples\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_features\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    172\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 173\u001b[1;33m         \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcheck_consistent_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mqids\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    174\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkind\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'O'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    175\u001b[0m             \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\pramo\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    229\u001b[0m     \"\"\"\n\u001b[0;32m    230\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 231\u001b[1;33m     \u001b[0mlengths\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0m_num_samples\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mX\u001b[0m \u001b[1;32min\u001b[0m \u001b[0marrays\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mX\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    232\u001b[0m     \u001b[0muniques\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    233\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\pramo\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    229\u001b[0m     \"\"\"\n\u001b[0;32m    230\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 231\u001b[1;33m     \u001b[0mlengths\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0m_num_samples\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mX\u001b[0m \u001b[1;32min\u001b[0m \u001b[0marrays\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mX\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    232\u001b[0m     \u001b[0muniques\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    233\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\pramo\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36m_num_samples\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m    140\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    141\u001b[0m             raise TypeError(\"Singleton array %r cannot be considered\"\n\u001b[1;32m--> 142\u001b[1;33m                             \" a valid collection.\" % x)\n\u001b[0m\u001b[0;32m    143\u001b[0m         \u001b[1;31m# Check that shape is returning an integer or default to len\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    144\u001b[0m         \u001b[1;31m# Dask dataframes may not return numeric shape[0] value\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: Singleton array True cannot be considered a valid collection."
     ]
    }
   ],
   "source": [
    "metric = pyltr.metrics.NDCG(k=10)\n",
    "    \n",
    "# monitor = pyltr.models.monitors.ValidationMonitor(\n",
    "#     X_test, y_test, Vqids, metric=metric, stop_after=250)\n",
    "\n",
    "model = pyltr.models.LambdaMART(\n",
    "    metric=metric,\n",
    "    n_estimators=1000,\n",
    "    learning_rate=0.02,\n",
    "    max_features=0.5,\n",
    "    query_subsample=0.5,\n",
    "    max_leaf_nodes=10,\n",
    "    min_samples_leaf=64,\n",
    "    verbose=1,\n",
    ")\n",
    "\n",
    "model.fit(X_train, y_train, X_train.any())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Epred = model.predict(x_test)\n",
    "print 'Random ranking:', metric.calc_mean_random(Eqids, Ey)\n",
    "print 'Our model:', metric.calc_mean(Eqids, Ey, Epred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
